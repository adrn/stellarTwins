% This project is part of the stellarTwins project.
% Copyright 2017 the authors.

% # To-do list
% - zeroth draft the introduction
% - zeroth draft the method section
% - zeroth draft the assumptions list
% - reformat single-column

\documentclass[12pt, preprint]{aastex6}
\hypersetup{colorlinks = false}

%% Begin DWH mods
\setlength{\voffset}{0in}
\setlength{\hoffset}{0in}
\setlength{\textwidth}{6in}
\setlength{\textheight}{9in}
\setlength{\headheight}{0ex}
\setlength{\footnotesep}{0in}
\setlength{\topmargin}{-\headsep}
\setlength{\oddsidemargin}{0.25in}
\setlength{\evensidemargin}{0.25in}
\linespread{1.09}
\setlength{\parindent}{1.2\baselineskip}
\makeatletter % you know you are living your life wrong when you need to do this
\long\def\frontmatter@title@above{
\vspace*{-\headsep}\vspace*{\headheight}
\noindent\footnotesize
{\noindent\footnotesize\textsc{\@journalinfo}}\par
{\noindent\scriptsize Preprint typeset using \LaTeX\ style AASTeX6
with modifications by DWH.
}\par\vspace*{-\baselineskip}\vspace*{0.625in}
}%
\long\def\frontmatter@abstractheading{%
\makeaffils
  \vspace*{-\baselineskip}\vspace*{1.5pt}
  \vspace*{0.13189in}
 \begingroup
  \centering
  \abstractname
  \vskip 1mm
  \par
 \endgroup
 \everypar{\rightskip=0.0in\leftskip=\rightskip}\par
}%
\def\frontmatter@keys@format{\vspace*{0.5mm}%
  \settowidth{\keys@width}{\normalsize\@keys@name}%
  \rightskip=0.0in\leftskip=\rightskip\parindent=0pt%
    \hangindent=\keys@width\hangafter=1\normalsize\raggedright}%
\def\twodigits#1{\ifnum#1<10 0\fi\the#1}
\def\mydate{\leavevmode\hbox{\the\year-\twodigits\month-\twodigits\day}}
\makeatother
%% End DWH mods

\newcommand{\acronym}[1]{{\small{#1}}}
\newcommand{\project}[1]{\textsl{#1}}
\newcommand{\tgas}{\project{\acronym{TGAS}}}
\newcommand{\tmass}{\project{\acronym{2MASS}}}
\newcommand{\gaia}{\project{Gaia}}
\newcommand{\xd}{\acronym{XD}}
\newcommand{\cmd}{\acronym{CMD}}

\newcommand{\myemail}{landerson@simonsfoundation.org}
\slugcomment{Draft manuscript not ready for distribution. \textbf{Copyright 2017 the authors.}}
\shorttitle{Improving Gaia parallaxes}
\shortauthors{Anderson, Hogg, Leistedt, Price-Whelan}
\begin{document}\sloppy\sloppypar\raggedbottom\frenchspacing

\title{Improving \textsl{Gaia} parallaxes
       with a data-driven model of the color--magnitude diagram}
\author{Lauren Anderson\altaffilmark{1},
        David W. Hogg\altaffilmark{1,2,3,4},
        Boris Leistedt\altaffilmark{2},
        Adrian Price-Whelan\altaffilmark{5}}
\altaffiltext{1}{Center for Computational Astrophysics, Flatiron Institute, Simons Foundation, New York City}
\altaffiltext{2}{Center for Cosmology and Particle Physics, Department of Physics, New York University}
\altaffiltext{3}{Center for Data Science, New York University}
\altaffiltext{4}{Max-Planck-Institut f\"ur Astronomie, Heidelberg}
\altaffiltext{5}{Princeton University Observatory, Princeton University}

\begin{abstract}
The \gaia\ \tgas\ \project{Catalog} contains more than 2 million parallax measurements.
Conversion of a noisy parallax measurement into a posterior belief over distances requires inference with a prior.
Usually this prior represents some kind of belief about the Milky Way.
However, there is multi-band photometry for the \tgas\ stars from imaging surveys;
this imaging is incredibly informative about stellar distances.
Here we use color information on \tgas\ stars from \tmass\ to build a noise-deconvolved empirical prior distribution of stars in color--magnitude space.
This data-driven model contains no knowledge of the physics of stellar interiors or photospheres, nor of the Milky Way, but rather derives its precision from its generative model of noisy parallax measurements and an assumption of stationarity.
We use the Extreme Deconvolution (\xd) algorithm, which is an Empirical Bayes approximation to a full hierarchical model of the true parallax and photometry of every star.
The algorithm is run not in absolute-magnitude space but in a transformed space where the measurement uncertainty is closer to Gaussian.
The \xd-optimized prior is used to perform parallax and distance inferences for every star, yielding a precise stellar distance estimate and uncertainty (and full posterior) for every star.
Our posterior parallax estimates are more precise than the Gaia catalog outputs by a factor of [XXX] for the median \tgas\ star; and more precise than previous examples of Bayesian distance estimates by a factor of [YYY].
The precision can be attributed to the statistics concept of shrinkage.
We independently validate our distances by looking at members of Milky Way star clusters; for example, M67 is not visible at all in the \tgas\ parallax estimates, but appears clearly in our posterior parallax estimates.
All our results, including a posterior parallax and distance sampling for [ZZZ] \tgas\ stars, are available in companion electronic tables.
\end{abstract}

\keywords{
  catalogs
  ---
  Hertzsprung--Russell and C--M diagrams
  ---
  methods: statistical
  ---
  parallaxes
  ---
  stars: distances
  ---
  stars: statistics
}

\section{Introduction}

The \gaia\ Mission (DWH CITE) will deliver more than a billion stellar distances.
Only a small fraction (but large number) of these distance
measurements will be purely astrometric:
\gaia\ uses astrometric parallax to determine the distances of the closer
stars, and calibrate spectrophotometric models.
These spectrophotometric models, in turn, along with \gaia's on-board
low-resolution $B_p\,R_p$ spectrophotometry, are used to provide
distance estimates to more distant stars (DWH CITE).
The full stack required for these distance inferences is complex.
It involves modeling not just stars, but also the dust in the Milky Way,
and the response of the telescope itself (DWH CITE).

With projects like \project{The Cannon} (DWH CITE) and \project{Avast}
(DWH CITE), we are exploring the extent to which our predictive models of
stars could be purely data-driven or statistical.
That is, under what circumstances could the data themselves deliver
more precise or more accurate information than any theoretical or
physics-based model?
The answer to this question is extremely context-dependent: It depends
on what data are available, how much data are available, and what
questions are being asked.
In general, data-driven models contain fewer assumptions than
physics-driven models, but they are also usually less interpretable.
However, the \gaia\ use case is ideal for thinking about purely statistical
models of stars:
The distance to a star is a simple latent variable, and the nearby
stars constitute a high signal-to-noise ``training set''.
These nearby stars can be used to anchor empirical models that can
then be applied to the more distant stars.

Here we deliver a demonstration-of-concept project that shows that a
data-driven model of the \gaia\ data could in principle deliver very
precise distances, without any input of the physics or numerical models of stellar
evolution, interiors, or photospheres.
Most stellar models used to generate photometric distances or photometric
parallaxes have been physical models, based on gravity, fluid mechanics,
radiative transfer, nuclear reactions, and atomic and molecular transitions.
Because there are small issues with each of these components, there are small
color and luminosity differences with the data---the models are wrong in detail---and
the physical models therefore produce distance estimates that are biased.
Besides, they build a long list of physical assumptions (about
nuclear reactions, convection, and thermal timescales, for example)
into the distance estimates.
That is, it is impossible, when using physical models,
to deliver photometric distance estimates that involve minimal assumptions.

However, the use of physical models for distance estimation is not necessary.
Because there are stars at all luminosities with good parallax information,
it is possible to build a stellar photometric model from the data themselves.
Different stars are observed at different levels of parallax precision,
so it requires relatively high technology to build this data-driven model
using all the data available, fairly and responsibly.
We have this technology!

Here we build and use just such a data-driven model.
In particular, we use all of the \gaia\ \tgas\ data, matched to the \tmass\
photometry, to make a model of the noise-free (or low-noise)
color--magnitude diagram (\cmd) of stars.
We use
an Empirical-Bayes approach known as Extreme Deconvolution (DWH CITE).
This method deconvolves heteroskedastic data to derive an estimate
of the noise-free or low-noise distribution that \emph{would have}
been observed with far better data.
This method has been used in astrophysics
previously to model the velocity distribution of stars in the Solar
Neighborhood (DWH CITE BOTH) and to perform quasar target selection
in \project{Sloan Digital Sky Survey} data (DWH CITE BOTH).
Its advantage over other deconvolution methods is that it takes as input,
and handles in a principled way, heteroskedastic data.
Its principle disadvantage for the present purposes is that it requires
or implies a strictly Gaussian noise model.
In the below, this requires us to transform the \cmd\ to a space in which
the noise is approximately Gaussian.

The novel use of \xd\ here is to treat its output---the deconvolved \cmd---as
a prior for use in inference of individual-star distances.
These inferences, one per star, provide much more precise parallax, distance,
or absolute magnitude estimates than we get from each star's primary
\tgas\ parallax measurement alone.
That is, we are using the \xd\ model to de-noise the \gaia\ parallax
measurements.
Technically, since \xd\ produces a maximum-marginalized-likelihood estimator
of the deconvolved distribution,
its use as a prior is only approximately valid; it constitutes using the
data twice.
However, since the data set is large, the \xd\ approximation is not bad; it is
sometimes known as the ``empirical Bayes'' method, and is well studied (DWH REFS).

It wouldn't be using the data twice---that is, it would be valid from a
probabilistic perspective---if we performed a full hierarchical Bayesian
inference.
Exploration of that possibility, and its computational tractability,
is among our long-term goals and motivations.
Along those lines, this paper can be seen as a companion to
a related project (CITE BORIS), in which we use a
somewhat less flexible model for the \cmd, but in which we take a much more principled
approach to the inference.

On a different tack, there has been some discussion in the literature
about how to use a parallax responsibly to infer a distance (CITE TRI+CBJ).
These papers use the \gaia\ measurement to construct a parallax likelihood,
and combine this with a distance prior.
While this is sensible and correct, all present methods proposed along
these lines build in informative (and known-to-be-wrong) assumptions
about the line-of-sight distance distribution to \gaia\ stars.
That is, they build in strong and informative assumptions about the Milky
Way.
The methodology presented in this paper makes exceedingly weak assumptions
about the Milky Way, and similarly weak assumptions about the properties of
stars.
The strongest new assumption made in this work is that for every star
in \tgas, there are other, photometrically (and bolometrically)
similar stars.
That is a much weaker assumption than has been made in other Bayesian
distance estimations.

This project is fundamentally a demonstration of concept:
We are only using the ``small'' (relative to the expected final \gaia\ data set)
\tgas\ Catalog.
We are performing only an approximation to full Bayesian hierarchical inference.
We have to use photometry that is ground-based, rather than the full-precision,
space-based photometry that the \gaia\ Mission will deliver.
However, as we show below, we get very good results.
It is promising that we will be able to obtain similar or even better results
in later \gaia\ data releases, and eventually put distances on $>10^9$
\gaia\ stars using photometric distance methodologies but without any
commitment to---or even use of---physical models of stars or the Milky Way.

\section{Assumptions and methods}

We build a prior for the distance measurement of Gaia stars using the Gaia measured parallaxes plus APASS photometry to build a color-magnitude-like diagram that serves as the prior for distance measurements of Gaia stars. Instead of making assumptions about the physical distributions of stars in the galaxy, or using stellar models for the modeled HR diagram of stars, we build a prior from the data themselves.

LA: Insert itemized or enumerated list of assumptions here. DWH will
typeset it to look okay! Be exhaustive and then we will edit down.

magSN = parallaxSN = 16 (excluding systematic parallax error in tgas)
train gaussian means, mus, Vs on progressively lower SN dataset

\begin{equation}
\label{eq:bayes}
P(\theta|\textbf{E}, \textbf{I}) = P(\theta ) \frac{P(\textbf{E} |\theta,\textbf{I})}{P(\textbf{E})},
\end{equation}


where $\theta$ is the model parameters that generate the evidence $\textbf{E}$, and P($\theta$) is the prior knowledge of the model, and $P(\textbf{E} |\theta,\textbf{I})$ is the likelihood of the evidence, given the model and some other prior assumptions. Our evidence is the parallaxes and G band magnitudes from Gaia, and the B and V band magnitudes from APASS. We build the prior from this evidence using extreme deconvolution


Crossvalidation

\section{Data and results}

We use stars cross matched in the TGAS and APASS set of observations. We require there are no NaNs in any APASS photometric band, as well as every band having positive errors. We check that the match between APASS and TGAS is good using extreme APASS-WISE colors. We correct for dust using 3D Bayestar (Schlafly+Finkbeiner) with an estimate of the distance from sampling of posterior Gaia distances from Adrain. There is minimal dust to the matched stars. To build our model here we use the Gaia G band magnitude, parallax and APASS B-V color.

\subsection{Dust}

Dust corrections are non trivial for stars with poor signal to noise. Stars with poor signal to noise have a likelihood that is consistent with infinite distance and can therefore have severe dust corrections. This is most obvious in the giants, which tend to have the lowest signal to noise, and can therefore have dust corrections $\sim 1-2$ magnitudes. To apply a dust correction to the 2MASS photometry, we first generate our prior using \xd\ on the observed, attenuated photometry. Using this raw prior we infer the distances to all the stars in our prior more precisely, increasing our signal to noise for each star and therefore minimize severe distances and their associated severe dust corrections. With more precise distance posteriors, we take the $5\%$ quantile of each distance posterior, so the closest bit of the posterior, and sample the Green et al 3D dust map at that distance. For each distance we take the median of the samples of the dust model. We apply each dust correction to our 2MASS photometry given by Equation \ref{eq:dust} where $K_{\lambda}$ = [3.626, 2.742, 3.303, 2.285, 1.698] for bands [B, V, g, r, i] respectively, taken from table (REF TABLE SFD), and $E(B-V)$ is the output of the Green et al dust models. We then regenerate our prior using the dust corrected photometry. We do not update the errors, but keep them the same as before the dust correction, which is wrong and under representing our errors but this leads again to a lighter deconvolution. Should I quote some statistics about the dust corrections? mostly small? maybe difference before after correcting for distance?

\begin{equation}
\label{eq:dust}
m_{\mathrm{band, corrected}} = m_{\mathrm{band}} - K_{\lambda} \times E(B-V)
\end{equation}

\section{Discussion}

We have shown that it is possible to obtain photometric parallaxes for
distant stars in the \gaia\ \tgas\ data without any use of physical stellar
models, nor models of the Milky Way.
We obtained these by building a data-driven model of the
color--magnitude diagram (\cmd) of the stars in the \tgas\ data set,
and using it as a prior pdf for Bayesian interences.
The posterior pdfs for distance that we obtain are, in general, much
narrower than the likelihood functions delivered by the
\gaia\ Mission, and therefore the distance estimates (or,
equivalently, parallax estimates) are much more precise.
It is not surprising that a Bayesian inference provides more
precise inferences than the likelihood function alone; Bayesian
inferences bring in new information that decrease variance (but
often introduce bias).
We have shown thatm, in addition to pure precision improvements, at
least some aspects of \emph{accuracy} have been improved as well, by
showing that the posterior distance estimates to stars in stellar
clusters are much more clustered than likelihood-based distance
estimates.

Although we have not performed principled hierarchical Bayesian inference in this
project, we built our prior for each star's distance by
performing a statistically responsible deconvolution
of the \gaia\ \tgas\ data that is justifiable under a clear set of
assumptions.
This deconvolution makes use of a reasonable noise model and an
assumption of stationarity to shrink the parallax uncertainties, and
do so dramatically for the stars measured at lower signal-to-noise.
Because the method we use (Extreme Deconvolution or \xd, which is
an Empirical Bayesian maximum-marginalized-likelihood estimator) accounts for
heteroskedastic noise, we were able to build our photometric parallax
model---which is a model of the \cmd---using
all the data, not just the data with the highest signal-to-noise or
largest parallaxes.
That is, the model for the \cmd\ we have built is representative for
the \tgas\ Catalog.
Inasmuch as that is true, we expect any (sensible) distance estimates
we generate from our distance posterior pdfs to be weakly biased.

What would be different if we wanted a model not of the \tgas\ data,
but a model appropriate for the full billion stars, or for a
volume-limited sample of stars?
How could we convert our existing results?
How would we do it properly in general?

Come back to the assumptions. What happens if we change or violate them?

Long discussion of the noise model. We took serious short-cuts. Call out to Boris.

Long discussion of dust.

Some discussion of possible failure modes. Including very rare kinds of stars.

Number of gaussians in \xd, and the w parameter. That we set them heuristically.

How this compares to other Bayesian attempts at inferring distances,
like, eg, the Tri--Coryn papers. Favorably! And with \emph{fewer}
assumptions, in fact!

\acknowledgments It is a pleasure to thank
  Jo Bovy (Toronto),
  Andy Casey (Monash),
and the attendees at the Stars Group Meeting at the Flatiron Institute
Center for Computational Astrophysics for comments and input.

This project was developed in part at the 2016 \acronym{NYC} Gaia Sprint, hosted
by the Center for Computational Astrophysics at the Simons Foundation
in New York City.

This work has made use of data from the European Space Agency (\acronym{ESA})
mission Gaia (http://www.cosmos.esa.int/gaia), processed by the Gaia
Data Processing and Analysis Consortium (\acronym{DPAC},
http://www.cosmos.esa.int/web/gaia/dpac/consortium). Funding for the
\acronym{DPAC} has been provided by national institutions, in particular the
institutions participating in the Gaia Multilateral Agreement.

[IS THERE A \tmass\ ACKNOWLEDGEMENT?]

This project was partially supported by [DWH GIVE GRANT NUMBERS]. It
made use of the \acronym{NASA} Astrophysics Data System.

\appendix

\section{Appendix material}


%\begin{thebibliography}{}
%\end{thebibliography}

\clearpage

\end{document}



%%
%% End of file `sample.tex'.
